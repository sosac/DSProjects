{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using ```tweepy``` for Data Mining\n",
    "\n",
    "This is an introduction to data collection from <a href=\"http://www.twitter.com/\">Twitter</a> using the ```tweepy``` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### DS 710: final project: collect and analyze twitter data\n",
    "### Connie Sosa: 11/30/2015\n",
    "\n",
    "# You must install the tweepy package before using it!\n",
    "import twitter\n",
    "import tweepy\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to set up an app at <a href=\"https://apps.twitter.com/\">apps.twitter.com</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save your consumer key, consumer secret, access token, and access secret here.\n",
    "# Don't share these secrets with others!  If you're building code for Twitter which many people will share,\n",
    "# you should encrypt this information.  \n",
    "# It's also possible to generate access tokens and secrets from within an app.\n",
    "\n",
    "con_key = 'bdCAhjLwnAguqzNqVr2ucHN5Q'\n",
    "con_secret = '7z65BYKQpJIRA1tuE05XUb8MwjstV5iLHMAITxUMV54ekBHZMT'\n",
    "acc_token = '4293166817-xzOF6TKYNVRyNvy3fpN9MhAtNUdDZibxx3SFZeV'\n",
    "acc_secret = '74ZX10bhpr4KPHFQVbDDKQ7onU4fbVUPmw5s4SBMwntTJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#\n",
    "# get_tweepy_api(): Return authenticated twitter service api\n",
    "#\n",
    "###############################################################################\n",
    "def get_tweepy_api():\n",
    "    #Use tweepy.OAuthHandler to create an authentication using the given key and secret\n",
    "    auth = tweepy.OAuthHandler(consumer_key=con_key, consumer_secret=con_secret)\n",
    "    auth.set_access_token(acc_token, acc_secret)\n",
    "\n",
    "    #Connect to the Twitter API using the authentication\n",
    "    api = tweepy.API(auth)\n",
    "    return api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#\n",
    "# get_twitter_api(): Return authenticated twitter service api\n",
    "#\n",
    "###############################################################################\n",
    "def get_twitter_api():\n",
    "\n",
    "    auth = twitter.oauth.OAuth(acc_token, acc_secret, con_key, con_secret)\n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    " \n",
    "    return twitter_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF Band Day/Night . 80m-40m  Poor/Fair . 30m-20m  Fair/Fair . 17m-15m  Fair/Fair . 12m-10m  Poor/Poor #hamradio #hamr\n"
     ]
    }
   ],
   "source": [
    "tweet_list = api.search(q='hamradio')\n",
    "len(tweet_list)\n",
    "\n",
    "def print_tweet(tweet):\n",
    "    print(tweet.text)\n",
    "    \n",
    "tweet=tweet_list[1]\n",
    "print_tweet(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#\n",
    "# twitter_search(): Search twitter in batches. From [MINING the Social Web by M. Russell]\n",
    "#\n",
    "###############################################################################\n",
    "def twitter_search(twitter_api, q, max_results=200, **kw):\n",
    "\n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets and \n",
    "    # https://dev.twitter.com/docs/using-search for details on advanced \n",
    "    # search criteria that may be useful for keyword arguments\n",
    "\n",
    "    search_results = twitter_api.search.tweets(q=q, count=100, **kw)\n",
    "#    search_results = twitter_api.search(q=q, count=100, **kw)\n",
    "    statuses = search_results['statuses']\n",
    "    \n",
    "    # Iterate through batches of results by following the cursor until we\n",
    "    # reach the desired number of results, keeping in mind that OAuth users\n",
    "    # can \"only\" make 180 search queries per 15-minute interval. See\n",
    "    # https://dev.twitter.com/docs/rate-limiting/1.1/limits\n",
    "    # for details. A reasonable number of results is ~1000, although\n",
    "    # that number of results may not exist for all queries.\n",
    "    \n",
    "    # Enforce a reasonable limit\n",
    "    max_results = min(1000, max_results)\n",
    "    \n",
    "    for _ in range(10): # 10*100 = 1000\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError as e: # No more results when next_results doesn't exist\n",
    "            break\n",
    "#        except e: # No more results when next_results doesn't exist\n",
    "#            break\n",
    "            \n",
    "        # Create a dictionary from next_results, which has the following form:\n",
    "        # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "        kwargs = dict([ kv.split('=') \n",
    "                for kv in next_results[1:].split(\"&\") ])\n",
    "        \n",
    "#        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        search_results = twitter_api.search(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "        \n",
    "        if len(statuses) > max_results: \n",
    "            break\n",
    "            \n",
    "    return statuses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The REST API\n",
    "\n",
    "Twitter has two versions of its API.\n",
    "\n",
    "The REST API allows you to _pull_ information from Twitter, or _push_ information back to Twitter.  We'll use the REST API to run a specific search.  You could also use the REST API to make automatic tweets on Twitter, or get information about specific users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#\n",
    "# save_json(): Save to JSON. From [MINING].\n",
    "#\n",
    "###############################################################################\n",
    "def save_json(filename, data):\n",
    "    print (\"In save_json()\")\n",
    "    with io.open('storage/{0}.json'.format(filename), \n",
    "                 'w', encoding='utf-8') as f:\n",
    "        f.write(unicode(json.dumps(data, ensure_ascii=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#\n",
    "# load_json(): Save to JSON.  From [MINING].\n",
    "#\n",
    "###############################################################################\n",
    "def load_json(filename):\n",
    "    print (\"In load_json()\")\n",
    "    with io.open('storage/{0}.json'.format(filename), \n",
    "                 encoding='utf-8') as f:\n",
    "        return f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#\n",
    "# call_tweepy_search_sample()\n",
    "#\n",
    "###############################################################################\n",
    "def call_tweepy_search_sample():\n",
    "    api = get_tweepy_api()\n",
    "\n",
    "    tweet_list = api.search(q='#%23hamradio')\n",
    "    tweet_list[0]\n",
    "    dir(tweet_list[0])\n",
    "\n",
    "#    for tweet in tweet_list:\n",
    "#       print tweet.text\n",
    "    [tweet.text for tweet in tweet_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#\n",
    "# call_simple_twitter_search_sample()\n",
    "#\n",
    "###############################################################################\n",
    "def call_simple_twitter_search_sample():\n",
    "    api = get_twitter_api()\n",
    "\n",
    "    tweet_list = api.search(q='bigdata')\n",
    "    tweet_list[0]\n",
    "    dir(tweet_list[0])\n",
    "\n",
    "    for tweet in tweet_list:\n",
    "       print( tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve a SearchResult object for each tweet, full of data such as the language, the identity of the poster, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# call_twitter_search_sample()\n",
    "###############################################################################\n",
    "def call_twitter_search_sample():\n",
    "    twitter_service_api = get_twitter_api()\n",
    "    q='#%23hamradio'\n",
    "    results = twitter_search(twitter_service_api, q, max_results=100)\n",
    "        \n",
    "    ## Show one sample search result by slicing the list...\n",
    "    for i in range(100):\n",
    "        print (json.dumps(results[i], indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TwitterHTTPError",
     "evalue": "Twitter sent status 404 for URL: 1.1/search.json using parameters: (oauth_consumer_key=bdCAhjLwnAguqzNqVr2ucHN5Q&oauth_nonce=2571453778550442222&oauth_signature_method=HMAC-SHA1&oauth_timestamp=1449546054&oauth_token=4293166817-xzOF6TKYNVRyNvy3fpN9MhAtNUdDZibxx3SFZeV&oauth_version=1.0&q=bigdata&oauth_signature=qvkRvk3t72xUJcltmNidy5cHbFI%3D)\ndetails: {'errors': [{'code': 34, 'message': 'Sorry, that page does not exist'}]}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\twitter\\api.py\u001b[0m in \u001b[0;36m_handle_response\u001b[1;34m(self, req, uri, arg_data, _timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib_request\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Content-Type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'image/jpeg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'image/png'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    468\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    578\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 579\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    506\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTwitterHTTPError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-b1d4a8a5c2f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcall_simple_twitter_search_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-52-b0974870e8ce>\u001b[0m in \u001b[0;36mcall_simple_twitter_search_sample\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_twitter_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtweet_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bigdata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mtweet_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\twitter\\api.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_response_with_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\twitter\\api.py\u001b[0m in \u001b[0;36m_handle_response\u001b[1;34m(self, req, uri, arg_data, _timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTwitterHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_response_with_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTwitterHTTPError\u001b[0m: Twitter sent status 404 for URL: 1.1/search.json using parameters: (oauth_consumer_key=bdCAhjLwnAguqzNqVr2ucHN5Q&oauth_nonce=2571453778550442222&oauth_signature_method=HMAC-SHA1&oauth_timestamp=1449546054&oauth_token=4293166817-xzOF6TKYNVRyNvy3fpN9MhAtNUdDZibxx3SFZeV&oauth_version=1.0&q=bigdata&oauth_signature=qvkRvk3t72xUJcltmNidy5cHbFI%3D)\ndetails: {'errors': [{'code': 34, 'message': 'Sorry, that page does not exist'}]}"
     ]
    }
   ],
   "source": [
    "call_simple_twitter_search_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_tweet(tweet):\n",
    "    print(tweet.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TwitterHTTPError",
     "evalue": "Twitter sent status 404 for URL: 1.1/search.json using parameters: (count=100&oauth_consumer_key=bdCAhjLwnAguqzNqVr2ucHN5Q&oauth_nonce=725011974824766513&oauth_signature_method=HMAC-SHA1&oauth_timestamp=1449543999&oauth_token=4293166817-xzOF6TKYNVRyNvy3fpN9MhAtNUdDZibxx3SFZeV&oauth_version=1.0&q=hamradio&oauth_signature=etYSyHvUFIsU69zRdj8b%2BqJhBoE%3D)\ndetails: {'errors': [{'code': 34, 'message': 'Sorry, that page does not exist'}]}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\twitter\\api.py\u001b[0m in \u001b[0;36m_handle_response\u001b[1;34m(self, req, uri, arg_data, _timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib_request\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Content-Type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'image/jpeg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'image/png'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    468\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    578\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 579\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    506\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTwitterHTTPError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-b6d235479c2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Step 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwitter_service_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"before dump json results\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-e824c3b6c5bf>\u001b[0m in \u001b[0;36mtwitter_search\u001b[1;34m(twitter_api, q, max_results, **kw)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#    search_results = twitter_api.search.tweets(q=q, count=100, **kw)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0msearch_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mstatuses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'statuses'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\twitter\\api.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_response_with_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\twitter\\api.py\u001b[0m in \u001b[0;36m_handle_response\u001b[1;34m(self, req, uri, arg_data, _timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTwitterHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_response_with_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTwitterHTTPError\u001b[0m: Twitter sent status 404 for URL: 1.1/search.json using parameters: (count=100&oauth_consumer_key=bdCAhjLwnAguqzNqVr2ucHN5Q&oauth_nonce=725011974824766513&oauth_signature_method=HMAC-SHA1&oauth_timestamp=1449543999&oauth_token=4293166817-xzOF6TKYNVRyNvy3fpN9MhAtNUdDZibxx3SFZeV&oauth_version=1.0&q=hamradio&oauth_signature=etYSyHvUFIsU69zRdj8b%2BqJhBoE%3D)\ndetails: {'errors': [{'code': 34, 'message': 'Sorry, that page does not exist'}]}"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "#### try to save it to json files but with all escapes.\n",
    "##########################################\n",
    "# Step 1\n",
    "twitter_service_api = get_twitter_api()\n",
    "\n",
    "#auth = tweepy.OAuthHandler(consumer_key=con_key, consumer_secret=con_secret)\n",
    "#auth.set_access_token(acc_token, acc_secret)\n",
    "#Connect to the Twitter API using the authentication\n",
    "#api = tweepy.API(auth)\n",
    "    \n",
    "q = \"hamradio\"\n",
    "\n",
    "# Step 2\n",
    "results = twitter_search(twitter_service_api, q, max_results=1000)\n",
    "\n",
    "print (\"before dump json results\")\n",
    "print (json.dumps(results, indent=1))\n",
    "\n",
    "##for i in range(100):\n",
    " ##   print json.dumps(results[i], indent=1)\n",
    "\n",
    "# Step 3\n",
    "print(\"before file write\")\n",
    "save_json(q, results)\n",
    "\n",
    "# Step 4\n",
    "print(\"before load_json\")\n",
    "read_results=load_json(q)\n",
    "\n",
    "print (\"before dump json read_results\")\n",
    "print (json.dumps(read_results, indent=1))\n",
    "\n",
    "##for i in range(100):\n",
    " ##   print json.dumps(read_results[i], indent=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ea16bf783ea6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muserInfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tweet' is not defined"
     ]
    }
   ],
   "source": [
    "userInfo = tweet.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweet_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-8139ef0f96ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweet_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tweet_list' is not defined"
     ]
    }
   ],
   "source": [
    "tweet_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweet_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-b17ea495e9b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweet_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tweet_list' is not defined"
     ]
    }
   ],
   "source": [
    "tweet_list[1]\n",
    "print (json.dumps(results, indent=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweet_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-467272f720a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#We can use the dir command to view a list of the attributes of each tweet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tweet_list' is not defined"
     ]
    }
   ],
   "source": [
    "#We can use the dir command to view a list of the attributes of each tweet\n",
    "\n",
    "dir(tweet_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweet_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-95601911c21b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Let's display the text of each tweet we found.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweet_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tweet_list' is not defined"
     ]
    }
   ],
   "source": [
    "#Let's display the text of each tweet we found.\n",
    "[tweet.test for tweet in tweet_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweet_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-b6d7835f0345>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweet_list\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;31m### id of the tweet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tweet_list' is not defined"
     ]
    }
   ],
   "source": [
    "[tweet.id for tweet in tweet_list]   ### id of the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweet_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-5ee8b52b0520>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeo\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweet_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tweet_list' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweet_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-d4dccb50065a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweet_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tweet_list' is not defined"
     ]
    }
   ],
   "source": [
    "[tweet.user for tweet in tweet_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Streaming API\n",
    "\n",
    "The Streaming API allows us to monitor Twitter in real time, grabbing tweets as they are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```tweepy``` package includes a class called ```StreamListener``` which monitors Twitter for us.  However, by default StreamListener does nothing with the tweets it collects.\n",
    "\n",
    "In this demonstration, we'll modify ```StreamListener``` to make a class that prints each tweet we're interested in to the screen.  Later, you may wish to create your own class which saves information from tweets to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We create a subclass of tweepy.StreamListener to add a response to on_status\n",
    "\n",
    "class PrintingStreamListener(tweepy.StreamListener):\n",
    "\n",
    "    def on_status(self, status):\n",
    "        print(status.text)\n",
    "        \n",
    "    #disconnect the stream if we receive an error message indicating we are overloading Twitter\n",
    "    \n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            #returning False in on_data disconnects the stream\n",
    "            return False\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created our subclass, we can set up our own Twitter stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### code from sentdex saving Tweets 2 of 3 and cleaning up tweets: how to use the twitter API v 1.1 w\n",
    "### with python to stream tweets 3 of 3.\n",
    "\n",
    "class PrintingStreamListener(tweepy.StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            print data\n",
    "            \n",
    "            tweetData = data.split(',\"')\n",
    "            saveFile = open('twitDB.csv', 'a')\n",
    "            saveFile.write(data)\n",
    "            saveFile.write('\\n')\n",
    "            saveFile.close()\n",
    "            return True\n",
    "        except BaseException, e:\n",
    "            print 'failed ondata,', str(e)\n",
    "            time.sleep(5)\n",
    "        \n",
    "    #disconnect the stream if we receive an error message indicating we are overloading Twitter\n",
    "    \n",
    "    def on_error(self, status):\n",
    "        print status\n",
    "        return False\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We create and authenticate an instance of our new ```PrintingStreamListener``` class\n",
    "\n",
    "my_stream_listener = PrintingStreamListener()\n",
    "my_stream = tweepy.Stream(auth = api.auth, listener=my_stream_listener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the ```track``` command to look for tweets with a specific keyword.  You can read more about constructing searches with ```track``` in the <a href=\"https://dev.twitter.com/streaming/overview/request-parameters#track\">Twitter API documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @KardashianReact: When a girl says \"first of all\" run away bc that means that she's prepared research, data, &amp; charts on your fuckup. Shâ€¦\n",
      "The fiddling with temperature data is the biggest science scandal ever | via @Telegraph https://t.co/N57Z5WsalY\n",
      "95% off Learning Python for Data Analysis and Visualization =&gt; https://t.co/oVT6u1HNPk ... #udemy #dataviz https://t.co/7WNrfvMnrr\n",
      "Better question: Have we explained why we want their data and how we could use it to better their experience.  #ascilite2015 2/2\n",
      "RT @wattsnextBen: OrganisationView #workometry @AndrewMarritt #HRTF2015\n",
      "#data https://t.co/ENDHDauXGi\n",
      "#admin #jobs Travel Data Analyst: Day to day admin and reporting of weekly sales figures to Manage... https://t.co/M9EjIqnouT #Colchester\n",
      "Hillary Clinton, Bernie Sanders support marijuana reform, citing faulty data - Washington Times https://t.co/BfbIKV7U7f\n",
      "@LuisMellet Hola, perdi toda mi data, estoy en el terruÃ±o, por mensaje privado enviame tus telfs. Abrazos, Vivian\n",
      "RT @whatsonANTV: 4 Pemenang Kuis Film #SunshineBecomesYou Harap Mengirmkan Data Lengkap Ke Email : whatson@an.tv Dengan Subjek : Pemenang Kâ€¦\n",
      "#Market #Manager Data Postpay Consumer (m/w) gesucht! #jobs #stelle https://t.co/AVaQyGm0kF\n",
      "RT @DarrellMoncus: The fiddling with temperature data is the biggest science scandal ever https://t.co/87Vy5j3az7 #globalwarming #climatechâ€¦\n",
      "Apply now to work for Mount Auburn Hospital as #Clinical #Data Coord./Meaningful Use Specialist in #Cambridge #jobs https://t.co/XJjgXelP9W\n",
      "RT @MattyMattRoss: Why can't Verizon have unlimited data ðŸ˜´ðŸ˜´ðŸ˜´ðŸ˜´\n",
      "RT @IBMbigdata: Data #analytics in a hybrid and fluid world https://t.co/QzQ6BgO3fd https://t.co/SnrkUlgSBM\n",
      "Ang bagal ng data\n",
      "@Ma3Route @NjururiBlamuel @ConsumersKenya @ntsa_kenya No Data is required to suspend Saccos like UMOINNER \"The thing speaks for itself \"\n",
      "Swisscom Operation Center https://t.co/OzvlYe6omc AVS Controlroom #avtweeps #architecture #intelliscreen #Datacenter https://t.co/PHQmaA5Pwo\n",
      "https://t.co/Xt8Q55onSG https://t.co/OH21cHHXNR https://t.co/75DpbIzKz3 htt...\n",
      "SENIOR SQL DBA - DATA WAREHOUSING! Contract. | Saul Recruitment - Give yourself one less thing to worry about https://t.co/Dedns8tQbh\n",
      "RT @EduRidden: Better question: Have we explained why we want their data and how we could use it to better their experience.  #ascilite2015â€¦\n",
      "RT: TomPinterest: RT: DigiBridgeSM: RT talkingblogs: #Pinterest Adds Location Data to Pins for Retailers: https://t.co/YuSPyKVu9c â€¦\n",
      "Big Data Processing  https://t.co/8A8gSAjnJm\n",
      "@monicabyrne13 The message is just data. Sending and receiving in a particular format (holographic) is about equipment and programming.\n",
      "ISLAMABAD: Election Commission Ki Website Heavy Data Aur Rush Ke Bais Bandh Hogai.\n",
      "\n",
      "Nawaz Memon.\n",
      "Data breach at Hong Kong toy maker VTech highlights broader problems https://t.co/tNokzsnq74\n",
      "RT @sighbaboo: Never forget these data on KI =&gt; https://t.co/DpH0cjDHTg ;\n",
      "https://t.co/qb2xPh3FDl\n",
      "@annwee13 @Cyunshuan I thought my data prob!! I open n wait for it to load.. ðŸ˜‚ðŸ˜‚Mana tau is memang like this de...  ä¸è¿‡ï¼Œè¿˜æ˜¯è¦è°¢è°¢ä½ ðŸ˜˜ðŸ˜˜ðŸ˜˜\n",
      "RT @AdorableWords: When a girl says \"first of all\" run away bc that means that she's prepared research, data, &amp; charts on your fuckup. She'â€¦\n",
      "RT :   RT javaspace71: \"TensorFlow Machine Learning System\" on Data Science Central  â€¦  https://t.co/tE4yK17iHX\n",
      "#ORACLE - sorting data by shifts:\n",
      "#HowTo\n",
      "https://t.co/yZQASPhHGP\n",
      "RT : Data-driven medicine: Sophia Genetics becomes largest clinical genomics network    https://t.co/kUxY8Ue0HZ\n",
      "RT @asadowaisi: News : Data on Muslims in police will no longer beÂ public\n",
      "https://t.co/EygRdKYTwd if SC,ST,OBC Data can be given why nt Musâ€¦\n",
      "RT @TimeXtender: How to reduce time spent on key data reporting by 75%? Automate your data warehouse #BI #DWA https://t.co/sR5t4hRR9j httpsâ€¦\n",
      "RT @EduRidden: Question: has anyone asked the student if they are willing to share their learning data.  #ascilite2015 1/2 https://t.co/6Gzâ€¦\n",
      "Nigerians complain about Vic O yet they download his songs and complain more; same people complain about MTN yet buy data and airtime daily\n",
      "@jewemcatubay Sorry to know this. Saw you mention Globe in your tweet. May I verify If this is your mobile data? :(\n",
      "2015-11-30 06:50:02.063383 -- latest data from 2015-11-30 06:38:38 - Temperature: 10.5 C - Humidity: 72 % - Wind: 10.2 km/h --\n",
      "Can i use my data to stream mama?\n",
      "RT @MattyMattRoss: Why can't Verizon have unlimited data ðŸ˜´ðŸ˜´ðŸ˜´ðŸ˜´\n",
      "[ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ]â—†ç›´æŽ¥ã”æ¥åº—ã®ãŠå®¢æ§˜ã¯2,000å††å‰²å¼•â—† https://t.co/jjx0BpBXvs [å¤§é˜ªåºœè°·ä¹(ä¸­å¤®åŒº)]è°·ä¹ãƒ›ãƒ†ãƒ˜ãƒ«é¢¨ä¿—ã€€å¦»å‘³å–°ã„è°·ä¹åº— #é¢¨ä¿— #å¤§é˜ªåºœ #è°·ä¹(ä¸­å¤®åŒº) https://t.co/QcAQblGdXo\n",
      "Example twitter weather data 06:50 AM 11.3Â°C 70 pct 9.6 km/h ESE%20%23wdisplay https://t.co/cgnJ2VYSrv\n",
      "IBM Spectrum Storage simplifies your storage infrastructure and optimizes data economics - - https://t.co/Dd0SN6iaUk\n",
      "Data hilang dari radar. Hate it ðŸ‘Š\n",
      "@BruunoBidelozzi @VidelmarWalter @nelson_rc17 no se me llego la data de que bruno se esta chamuyando a tu chica no quiero decir nada pero we\n",
      "TSN Tyson Foods Inc Cl A EOD Data\n",
      "https://t.co/BfAsrcbdIo\n",
      "\n",
      "$TSN $GS $HD $GBSN #TSN #share #pennystocks\n",
      "Latest Weather Data 4:20 PM 25.0C 51% 6.6 https://t.co/F2hi8bnypB\n",
      "RT @aguyader17: Instant #GameMap Clasic? #DENvsNE in overtime with #visualytics from drive data. https://t.co/Lt5gYa0Z61\n",
      "You haven't seen anything yet in Asia's e-commerce. 2015 data. \n",
      "India biggest potential. #ecommerce #china #india https://t.co/FMJUSrSNZM\n",
      "Hindi talaga magsesend yang picture sa snapchat kahit anong pilit mo kasi nga naka off ang data. Tingin tingin... https://t.co/XoMYUMFMVI\n",
      "Not all data should be treated equal. Learn to separate the useful from the \"nice to know\" https://t.co/dhQhiCbItJ\n",
      "#teamfollowback UPDATE 1-Data breach at HK toy maker VTech highlights broader problems https://t.co/3meISd08PF #sougofollow\n",
      "I should buy data before I use all this airtime up..\n",
      "Insight Brokers: Can MSPs Simplify Big Data for Business? https://t.co/bH37oiRFP2 via @danielnewmanUV\n",
      "@MTN180 @MTNNG . If I updated by the roadside, I'd understand. But I burnt fuel and went to your office. What happened to my bio-data? (5)\n",
      "@ChampChong Can't reset early! Would recommend adding a Data Pack if you need to reverse shaping: https://t.co/dZprXyHPQQ - @iiBri_\n",
      "The 5 Best Music Apps That Won't Tear Through All Your Data https://t.co/O6DPwnehXI\n",
      "RT @Ruthbarbetta: The fiddling with temperature data is the biggest science scandal ever - via @Telegraph https://t.co/BOLnPuYk1A\n",
      "[ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ]ç´ ç›´ãªå¿ƒã¨æ¥µä¸Šã‚µãƒ¼ãƒ“ã‚¹â™ª https://t.co/JVxcaIUZNa [æ±äº¬éƒ½å°æ±åŒº]æ±äº¬ãƒ‡ã‚¶ã‚¤ãƒ³ãƒªãƒ³ã‚°ä¸Šé‡Žåº— #é¢¨ä¿— #æ±äº¬éƒ½ #å°æ±åŒº https://t.co/LQTpFDJPML\n",
      " https://t.co/7ZsLYudeSv https://t.co/Gâ€¦\n",
      "RT Perficient_HC \"VIDEO: How NASCO Enhanced #UX and Brand Experience and Integrated for Data-Driven Results: https://t.co/IMBXPAd8MX #digiâ€¦\n",
      "weather data 06:50 - Temperatur:9.3oC - Windgeschwindigkeit:WSW12.9 km/h - Taupunkt:-3.3oC - Luftdruck:1011.5 hpa - Niederschlag :  0 mm\n",
      "#Germany #Retailers : Wolford : #Consumer sales trends during Nov 2015 is seen to be soft. https://t.co/An41xMczJk #Market #Data\n",
      "Andreea vrea sa reprezinte Romania, prima data in istorie, la o cursa de sanii trase de caini.... https://t.co/VdJJCZRDpN\n",
      "RT @ConsumersKenya: #ArriveAlive https://t.co/XdJeJMQvPz\n",
      "2015-11-30T05:48:29Z å²é˜œåœ°æ–¹æ°—è±¡å° ã€å²é˜œçœŒæ°—è±¡è­¦å ±ãƒ»æ³¨æ„å ±ã€‘ç¾Žæ¿ƒåœ°æ–¹ã§ã¯ã€ï¼‘æ—¥æœã¯éœœã«å¯¾ã™ã‚‹è¾²ä½œç‰©ã®ç®¡ç†ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ https://t.co/nVUwzcvlk2\n",
      "â˜…SDã‚«ãƒ¼ãƒ‰ãƒ»USBãƒ¡ãƒ¢ãƒªãƒ»å¤–ä»˜ã‘HDDãªã© ãƒ•ã‚¡ã‚¤ãƒ«å¾©å…ƒã‚„ã£ã¦ã¾ã™ï¼ åº—é ­æŒã¡è¾¼ã¿ã§ã‚‚éƒµé€ã§ã‚‚å—ã‘ä»˜ã‘ã¦ã„ã¾ã™ï¼ â˜…ã‚¹ãƒžãƒ¼ãƒˆãƒ¬ã‚¹ã‚­ãƒ¥ãƒ¼å‰ç¥¥å¯ºãƒ»å¾¡èŒ¶ãƒŽæ°´ 0422-26-9339 https://t.co/GlDUWMJCpB\n",
      "2015-11-30T05:48:29Z å²é˜œåœ°æ–¹æ°—è±¡å° ã€å²é˜œçœŒæ°—è±¡è­¦å ±ãƒ»æ³¨æ„å ±ã€‘ç¾Žæ¿ƒåœ°æ–¹ã§ã¯ã€ï¼‘æ—¥æœã¯éœœã«å¯¾ã™ã‚‹è¾²ä½œç‰©ã®ç®¡ç†ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ https://t.co/YFu5R37JGg\n",
      "Update Data AKB48 per 28 Februari 2015, selengkapnya cek https://t.co/Vbf7rq1Kvx\n",
      "RT @wattsnextBen: OrganisationView #workometry @AndrewMarritt #HRTF2015\n",
      "#data https://t.co/ENDHDauXGi\n",
      "Pas de data de SOWIFI Garage\n",
      "#à¤œà¤¯à¤¹à¤°à¥€à¤µà¤¿à¤ à¥à¤ à¤² sandymate4321: #à¤œà¤¯à¤¹à¤°à¥€à¤µà¤¿à¤ à¥à¤ à¤² DasiramJ: #à¤œà¤¯à¤¹à¤°à¥€à¤µà¤¿à¤ à¥à¤ à¤² meteash: #à¤œà¤¯à¤¹à¤°à¥€à¤µà¤¿à¤ à¥à¤ à¤² NemoFIndo: #à¤œà¤¯à¤¹à¤°à¥€à¤µà¤¿à¤ à¥à¤ à¤² Dataâ€¦ https://t.co/cQURjRAa4g\n",
      "AUD/USD: Jam packed data loaded week with plenty to look for - Westpac\n",
      "\n",
      "FXStreet (Delhi) â€“ Sean Callow, Research Ana https://t.co/x5DXXcPs1j\n",
      "[ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ]å¤§é˜ªå¸‚å†…ãªã‚‰äº¤é€šè²»ç„¡æ–™ï¼æœ€é«˜ã®ãŠæ™‚é–“ã‚’ãŠç´„æŸ https://t.co/OGCQtlFAKf [å¤§é˜ªåºœã‚­ã‚¿]å¦»å¤©ã€€äº¬æ©‹åº— #é¢¨ä¿— #å¤§é˜ªåºœ #ã‚­ã‚¿ https://t.co/HpUhS6WNIe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-53c3b3865b28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# You can pause the display of tweets by interrupting the Python kernel.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmy_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, follow, track, async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'delimited'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'stream.twitter.com'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_start\u001b[1;34m(self, async)\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[1;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[1;34m(self, resp)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# keep-alive new lines are expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mread_line\u001b[1;34m(self, sep)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_pop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m                     \u001b[1;31m# Close the connection when no data is returned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    498\u001b[0m             \u001b[1;31m# Amount is given, so call base class version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[1;31m# (which is implemented in terms of self.readinto)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHTTPResponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[1;31m# Amount is not given (unbounded read) so we must check self.length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    612\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m                     \u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;31m# Read the next chunk size from the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"chunk size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m    749\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                   self.__class__)\n\u001b[1;32m--> 751\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m                 \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m                 \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now, we're ready to start streaming!  We'll look for recent tweets which use the word \"data\".\n",
    "# You can pause the display of tweets by interrupting the Python kernel.\n",
    "\n",
    "my_stream.filter(track=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Even if you pause the display of tweets, your stream is still connected to Twitter!\n",
    "# To disconnect (for example, if you want to change which words you are searching for), \n",
    "# use the disconnect() function.\n",
    "\n",
    "my_stream.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
